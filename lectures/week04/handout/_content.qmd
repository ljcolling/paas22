As I said in the [previous lecture](), the focus of this course, and most of the
undergraduate research methods courses that you will take, will be on
quantitative methods. Today will be the start of our journey of learning more
about the specifics of **study design** in _quantitative_ _research_.

As we touched on in the [previous lecture](), _quantitative research_ is all
about **measurement**. The aim of _quantitative research_ is to take a
phenomenon and condense it down into a few **variables** than can be
**measured** as _precisely_ and _reliability_ as possible. We also saw that
_quantitative research_ often made use of statistical methods, and that the aim
of _quantitative_ _research_ was often to develop **generalisations** or
**generally applicable** theories. In today's lecture, we're going to learn a
bit about how to **design** quantitative studies so that _all these things are
possible_.

## The "how" of quantitative research

The conclusions that we can draw from our research depends on how that knowledge
was generated and the research design that was used. For any piece research that
we conduct (or piece of research that we read), we need to be able to answer
several questions: 1) How do we actually test **hypotheses** appropriately? 2)
How do we **generalise** our findings? 3) How to we **quantify** seemingly
unquantifiable things? The answer to these questions lies in **research
design**.

### Research design

We can use different types of research design to answer different **research
questions** and to test different **hypotheses**.[If you're not sure what the
terms **research question** and **hypothesis** mean, then just keep them in your
mind for now. Their meanings will become clearer when we get to the
examples.]{.aside} Study designs can vary along many dimensions. For example,
study designs can differ on whether they include a **manipulation** or not. They
can differ on whether they use a **between-subjects** or **within-subjects**
measurement. And they can differ with respect to the **time frame** used for
data collection.

<!--

// this is going to need a preview slide
Some study designs that vary on these dimensions include **observational designs**
and **correlational designs**.

We'll try to examine all of these dimensions by way of
examples.
-->

#### Experimental and non-experimental designs

The key feature of **experimental designs** is that there is some form of
**manipulation**. By **manipulation**, we just mean some sort of change that is
introduced that may have some impact on the thing our study is measuring.[The
**manipulation** might be something that is intentionally introduced by the
experiment, or it might be some change that is naturally occurring. We'll see
that this will be the difference between _true experiments_ and _natural
experiments_.]{.aside}

Not all possible designs include manipulations. Designs that don't include
manipulations are known as **observational** or **correlational** designs. In
correlational designs we rely on **observed data** that are not subjected to any
**experimental manipulation**. By _observational_, we don't mean that we're
_just looking_. There is still measurement, whether this is through
questionnaires, laboratory tasks, or similar.

**Correlational** designs have several **practical** advantages over
**experimental** designs. These include the ability to collect data from far
more people than would be practical for an experimental design. And they also
allow us to study phenomena where experimental manipulations would be
_unethical_. But correlational designs also have drawbacks when compared with
experimental designs. In particular, while correlational designs can be used to
investigate **relationships** between variables, but in order to make **causal**
claims, experimental designs (whether true experiments or natural experiments)
are needed.

## An example: Ice cream and murder

In @fig-murder we can see a plot of the relationship between the murder rate and
the number of ice creams sold in New York City. We can see from the plot that
when the murder rate is high then the number of ice cream sales is also high and
when the murder rate is low then the number of ice creams sold is also low. But
are they _just correlated_ or does ice cream _cause_ murder?

```{r}
#| echo: false
#| fig-align: center
#| fig-cap: The relationship between the murder rate and ice cream sales in New York City
#| label: fig-murder
knitr::include_graphics(here::here("images","IC.jpg"))
```

We might design to conduct some research into this relationship between ice
cream and murder to see whether there actually is some sort of causal
relationship. Obviously, there are **many** ethical issues with conducting an
experiment on this, but let's put those aside for now and see what such an
experiment might actually look like.

Our first step in our experiment would be to specify our **research question**.
In this example, our research question might be something like: _Does eating ice
cream make you more prone to murderous tendencies?_ From this we can now
formulate our **hypothesis**. In our **hypothesis** we will actually specify the
outcome we expect. Our hypothesis might be something like: _Eating ice cream
increases the desire to commit murder_.

Testing our hypothesis with an experiment might involve something like the
following steps: First, we might invite a bunch of people into lab. Half these
people will be given some ice cream eat, and the other half will not be given
some ice cream. This is our **manipulation**. Next, we might get all of our
participants to look at several images of people (our _stimuli_) while we get to
rate how much they want to **eliminate** them on a scale of 0 (no desire) to 9
(all the desire possible).

In this study, we have **independent variable** (IV) or _predictor variable_.
This is the thing that we're manipulating. In our case, this is whether people
ate ice cream or not. We manipulated our IV by assigning people to one of **two
groups**: The _ice cream condition_ or the _no ice cream condition_. We also
have one **dependent variable** (DV) or _outcome variable_. In our case, this
would be participants total score on our _desire to eliminate_ measure.

After we have all our data we could then compare the results between the _ice
cream **condition**_ and the _no ice cream **condition**_ to see which group
gave higher ratings for their _desire to eliminate people_ (the **outcome** or
**DV**).

## Features of good study design

Our study on the relationship between murder and ice cream is an example of a
very unethical study, but it is also a _poorly_ designed study. In a
well-designed experiment, we can be confident in saying our **manipulation**
_caused_ a change in our **outcome variable**. But this isn't the case for our
ice-cream study. Let's take a look at some features of good study design.

### Controls

Our imaginary study didn't use _any_ **controls**. We recruited all kinds of
people without giving consideration to how different characteristics might
affect our results. Let's say, for example, that all the people that we
recruited were actually lactose intolerant and that for these people eating
ice-cream caused a great deal of discomfort. Perhaps it is actually this
discomfort that caused their murderous rage and their murderous rage is not
specific to ice cream _per se_. It could equally well be caused by drinking
milkshakes.

We might also not have had a standardised set of instructions that we gave to
participants. Some participants might have arrived very hungry and other
participants might have arrived very full. Maybe the differences that we observe
are actually a result of some participants being very
[hangry](https://www.oxfordlearnersdictionaries.com/definition/english/hangry).

Maybe we didn't control our **IV** appropriately. We might have often changed
the brand or the flavour of the ice cream. Some days we might have run out of
ice cream and used _frozen yoghurt_ instead. And some days we might just have
given a small amount of ice-cream and other days we might have forced our
participants to eat a large amount of ice cream. Now we wouldn't know exactly
what cause any changes in our **outcome**.

We might also not have controlled the lab environment adequately. On some days
the heating might have been up really high. And other days the air-conditioning
might have been up really high. Maybe it's just the heat that's driving people
into a murderous rage?

### Randomisation

Another feature that might have been missing from our study is that we didn't
**randomly assign** people to groups: Maybe we did our participant recruitment
first at a dentist's office and then at supermarket. And maybe all participants
recruited first were assigned to the ice cream condition with the second batch
of participants assigned to the no ice cream condition. Because of this, it
might so happen to be the case that all the participants in the ice cream
condition just so happened to have sensitive teeth. This would affect the
results by giving us the impression that ice cream increases murderous
tendencies when it doesn't. To deal with these issues, participants should have
been sorted into groups **randomly**. A well-designed experiment would randomise
the **participant allocation** and the **stimulus presentation order** (in our
experiment, this refers to the order in which the images of faces were rated).

### Blinding

In our study, we might have told participants that we were interested in the
effect of ice cream on murderous tendencies. And we might have also given
participants the ice cream ourselves. Participants may have (consciously or not)
modified their behaviour to either fit the hypothesis or to contradict the
hypothesis. Because of this, it is crucial that participants are unaware of what
the hypothesis was and also what condition they have been allocated to. If
participants are na√Øve to group allocation then study is said to be
**single-blind**. If neither the participants nor the researcher know which
condition the participants are put in, then the study design is known as
**double-blind**. In such a case allocation might be recorded but only revealed
once the study is over and the data are being analysed.

### Theoretical framework

The choice of **predictor** (**IV**) and **outcome** (**DV**) variables does not
happen in a theoretical vacuum. Rather, these choices are based on theory. In
our experiment, the decision to have ice cream as the **IV** and murderous
tendencies as the **DV** was not based on any **theory**. It could be that
committing murder causes people to eat ice cream. In which case, we should
probably have swapped around our IV and DV. Or it might be that they're
completely unrelated. To have good reasons for running the experiment we did,
we'd would probably have to be able to tell some kind of a plausible story about
**how** eating ice cream a murder were related. Such a story would probably have
to make reference to some kind of psychologically or biologically plausible
mechanism that might explain the connection.

## Types of study designs

We've already talked about experimental designs through your example. But it's
worth spending a little more time talking about different kinds of study design.

### Experimental studies

First, we have **experimental studies**. Experimental studies usually have tight
controls. As a result, experimental studies can be somewhat artificial, because
they abstract away from reality. This means that experimental studies can
sometimes lack something called **ecological validity**. Ecological validity
refers to the ability to generalise the results of the study to **real-life**
settings. That is, just because something is true is the lab, doesn't
necessarily mean that it will be true in "the real world". Experimental designs
do, however, provide the most rigorous methodology for investigating **causal
relationships**.

As we saw in our example, good experimental design requires randomisation,
manipulation, and adequate controls. For many research questions there are
methodological, logistical, and ethical obstacles that make it infeasible to
conduct experiments. In these cases, we might want to use a
**quasi-experimental** design or a **natural experiment**.

### Quasi-experiments

**Quasi-experimental** designs are similar to experimental designs **expect for
participant randomisation**. As a result, they're used in situations where it's
not possible to randomise the allocation of participants into groups. An example
of a study using a **quasi-experimental** design might be one looking at the
effectiveness of attending summer school. If one school offers summer school,
but another does not, then we can't randomise students into the intervention. In
situations like this, we should still try to **match** the participants so that
the two groups don't differ on any Characteristics that might be relevant to our
outcome. Expect, of course, for the characteristic we're actually interested
in---attending summer school.

### Natural experiments

**Natural experiments** are studies where randomisation and manipulation occur
through **natural** or **socio-political** means. A good example of a **natural
experimental** might be _twin studies_. Identical twins share 100% of their
genes while fraternal twins only share on average 50% of their genes. However,
both kinds of twins tend to share the same home environment (if they're raised
together). By comparing similarities on some characteristic between identical
twins and between fraternal twins we might be able to estimate the degree of
variation of some characteristic that is due to genetic variation. Other
examples of natural experiments might be made possible by differences or changes
in government policy: For example, bans on cigarette advertising, or differences
in length on compulsory education. Natural events, or even natural disasters,
might create the manipulations that natural experiments can be based on.

## Aspects of study design

In our ice cream example, we used a between-subjects design, but this isn't the
only option available to us. We just collected our data at one point in time.
And this too isn't the only option available to us.

### With-subjects and between-subjects designs

In a **between-subjects** or **independent design** we compare different
**groups** of participants. For example, in our ice cream study, one **group**
of participants ate ice cream while the other **group** of participants did not.

Between-subjects designs can be contrasted with **within-subjects** or
**repeated measures** design. As the name suggested, this kind of design
involves _repeatedly measuring_ participants, but **under different
conditions**. We can show the distinction by way of an example. Let's say that I
conduct a study where I'm interested in whether people are better at remembering
long words or short words. A _between-subjects_ design would involve getting one
_group_ of participants to remember long words and another _group_ of
participants to remember short words. With a **within-subjects** design,
however, all participants would be asked to remember the words under both
conditions (short words and long words). We'd measure their memory for words
under both of these conditions.

With **within-subjects** designs there are some additional things than we will
need to consider. For example, if participants perform one condition first
followed by the other conditions then we might need to consider whether there
are order effects presents. It might be that participants are fatigued by the
time they get to the later condition and as a result they perform worse on it.
Or it might be the case that by the time they get to the later condition they
have already had some practise with the task and, therefore, they might perform
better.

Finally, we can mix **within-subject** manipulations with **between-subject**
manipulations. This is what is known as a **mixed-design**. To use our word
memory example above, an example of a **mixed-design** might be as follows:
First, we might split our participants in **two groups** and give one group some
special memory training. All participants would then be asked to perform the
word memory task. We could then examine whether the influence of the memory
training made a difference to whether people were better at remember short words
over long words.

### Time frame

<!-- change this header -->

In our ice cream example we also only took our measurements at one point in
time. But this too is not the only option available to us. We could for example
vary the time frame used. There are a couple of different ways in which we could
do this. First, in a **cross-sectional** design, we're still taking our
measurements at a single point in time

An alternative to a _cross-sectional_ design might be a **longitudinal design**.
This kind of design involves repeated measurement of the same characteristic of
the same participants at multiple different time points. The logistics involves
in **Longitudinal designs** can make them very difficult to carry out. This is
particularly true where studies carry on for several decades. This can also make
them very time-consuming and expensive to carry out. Finally, the risk of
**missing data** with longitudinal studies can also be very high.

### Missing data

Missing data can occur in all types of studies, not just longitudinal studies,
although the large-scale nature of them does make it more likely. Missing values
can also result from a number of different causes. For example, they might be a
result of technical failures (such a computer errors) that means answers don't
get registered or recorded properly. They might also occur because participants
accidentally skip questions. Or they might occur because participants
intentionally skip questions because they don't want to disclose some bit of
information---for example, information that might be of a sensitive nature.

The presence and pattern of missing data can sometimes be random, but sometimes
it is not. For example, you might have a survey that includes questions about
income, because you're interested in some relationship between income and some
characteristic. It might be the case that the missing data that you observe is a
result of one specific group of participants, for example, those from a low SES
background, skipping over those questions. By exploring the pattern and possible
causes of missing responses we can learn more about our data.

## Measurement

### Construct validity

A measure is **valid** if it measures what it is supposed to measure. In
psychology, we often want to measure things that maybe be difficult to observe
directly and difficult to **quantify**. For example, things like happiness, or
cognitive ability, or personality. We attempt to measure these unobservable
things using a range of different tools including questionnaires or experimental
tasks. We design these tools by using the theoretical underpinnings behind the
constructs we are trying to measure. **Construct validity** is the extent to
which a tool can be justifiably trusted to actually measure the construct it is
supposed to measure.

### External validity

A study has **external validity** if its findings can be applied to the entire
population of people with the relevant characteristics. For example, if study
uses a sample of white women in western cultures, the findings may only be true
for white women in western cultures. They might not apply or **generalise** to
_all_ people.

We've already touched on **ecological validity**. **Ecological validity**, which
is often an issue in experiments, refers to whether the findings of a study
apply to the "_real world_". Just because something is true in the lab doesn't
mean it is going to be true in the real world.

### Reliability

Finally, **reliability** refers to the **consistency** of a measure. A measure
is **reliable** if it produces consistent results each time it's used by the
same participant. For example, we could measure someone's maths anxiety with
a questionnaire. Our questionnaire would be considered **reliable** if when we
tested the same participant on different occasions they got similar scores each
time. This stability over time is known as **test-retest reliability**.

## Levels of Measurement

### Nominal/categorical

### Ordinal

### Interval

### Ratio

## Variable/Data Types
