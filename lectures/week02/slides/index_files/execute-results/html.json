{
  "hash": "f94c15d72f72e7f96323c55bfc2021b3",
  "result": {
    "markdown": "---\nformat: \n  sussex-revealjs:\n    center-title-slide: false\nnavbar: true\nweek: 2\ntype: slides\n---\n\n::: {.cell}\n\n:::\n\n\n\n<h2>Lecture 2</h2>\n\n<h1>What is this thing called science?</h1>\n\n<h2>Introduction to Philsophy of Science</h2>\n\n\n<br>\n<br>\n\n<h3 style=\"color:black;font-weight:normal\">Dr Lincoln Colling</h3>\n\n<h3 style=\"color:black;font-weight:normal\">03 Oct 2022</h3>\n\n<br>\n\n<span class=\"absolute\" style=\"bottom: 0; width:100%; text-align: center\">Psychology as a Science</span>\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/University_of_Sussex_Logo.svg/768px-University_of_Sussex_Logo.svg.png){.absolute top=440 left=1000 width=\"280\"}\n\n\n## Philosophy of Science \n\nThe title of this course is \"Psychology as a Science\". \n\n- But what is this thing called \"Science\"? \n\n- Is it a special way of learning about the world?\n\n- And if it is then what makes it special?\n\n\n\n## The common-sense view of science\n\nThe common-sense view might go something like this:\n\n> Science is special because it is knowledge **based on facts**\n\nScience is often contrasted with other forms of knowledge that might be \n\n  - based on authority (e.g., celebrities, religious and political leaders)\n  - revelation (e.g., personal religious or spiritual experiences)\n  - superstition (e.g., \"knowledge of the ancients\")\n  \n\n\nBut this raises two questions:  \n\n1. If science is based on facts, then where do \"facts\" come from?\n2. And how is knowledge then derived from these facts\n\n\n\n## Where do facts come from?\n\nThe **common-sense view of science** was formalised by two schools of thought: The _empiricists_ and the _positivists_\n\nTogether they held a view that went something like this:\n\n> _Knowledge should be derived from the facts of experience_\n<br>\n\nWe can break this idea down:\n\n1. Careful and unbiased observers can directly access facts through the senses/observation. \n\n2. Facts come before and are independent of, theories.\n\n3. Facts form a firm and reliable base for scientific knowledge. \n\n<br>\n**But is this true?**\n\n\n\n## Facts through the senses \n\n\nA simple story of a how the senses work is that there are some external physical causes (light, sound waves etc.) that produce some physical changes in our sense organs (e.g., our eyes) that are then registered by the brain. \n\nThis account implies direct and unmediated access to the world through our senses. But is this actually the case?\n\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n<img style=\"display:flex;margin-left:auto;margin-right:auto\" width=\"60%\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/My_Wife_and_My_Mother-in-Law.jpg/777px-My_Wife_and_My_Mother-in-Law.jpg\" />\n:::\n\n::: {.column width=\"60%\"}\n- This image could be seen as an old woman or a young woman. Some of you might see one and not the other while some might see both and switch between them.\n\n- The physical causes (the light hitting our eyes) is more-or-less the same for everyone, but you might \"see\" different things\n:::\n\n::::\n\n---\n\n### Observation is not \"theory-free\"\n\nThe previous example is just a toy example, but it reveals a larger point:\n\n<br>\n\nTwo scientists might \"observe\" something different even when looking at the same thing.\n\n<br>\n\nIn some fields, being able to make \"observations\" actually requires training.\n\n1. Training in how to observe stuff through a microscope \n\n2. Training in how to distinguish different kinds of behaviour \n\n3. Training in how to read an x-ray etc\n\n\n\nSo a simple claim that observations are \"unbiased\" or \"straightforwardly given by the senses\" seems to be false.\n\n\n\n## But what do we even mean by \"facts\"?\n\nWhen we think of a \"fact\" there are two things we could mean \n\n1. \"Fact\" could refer to some external state of the world \n\n2. Or **statements** about  those external states\n\n_The fact that **this university is in East Sussex**_ could refer to this actual university and its actual being in East Sussex \n\nor it could refer to the statement: \"This university is in East Sussex.\"\n\nWhen we talk about \"facts\" as the basis for science, we're talking about these statements.\n\nWe'll call this type of fact an \"observation statement.\"\n\n\n\n## Do facts come **before** theories?\n\nThink of a child learning the word apple:\n<blockquote>\nThey might initially imitate the word \"apple\" when shown an apple by their parent. \n\nNext, they might use the word \"apple\" when pointing to apples\n\nBut then one day they might see a tennis ball and say \"apple\". The parent would then correct them, and show them that a tennis ball isn't an apple because you can't, for example, bite into it like an apple\n\nBy the time the child can make accurate \"observation statements\" about the presence of apples they might already know a lot about the properties of apples (have an extensive \"theory of apples\")\n</blockquote>\n\nThe same goes for scientists; formulating observation statements might require substantial background knowledge or a conceptual framework to place them in.\n\nSo **observation statements** aren't completely **independent of theory**\n\n## Not just facts, but relevant facts\n\nLet's say that we've been able to acquire some facts. Will any old facts do?\n\nLet's take a simple example: \n\n<blockquote>\nYou observe that grass grows longer among the cowpats in a field. \n\n- You think this is because the dung traps moisture that helps the grass grow. \n\n- Your friend thinks this is because the dung acts as a fertiliser\n</blockquote>\n\nObservations alone can't distinguish these. To tell which is correct you need to **intervene** on the situation. \n\nFor example, grind up the dung so that it still fertilises the ground or use something else to trap the moisture. \n\n**Intervening**, for example, through experiment allows you to tell what the _relevant facts_ of your observation are \n\n## Active observation and intervention\n\nBy intervening on the system, we can tell which facts are **relevant**\n\n**But** _scientific theories_ may play a part in helping to determine what is and isn't relevant\n\n<blockquote>\n Example from the history of *cognitive psychology* \n\n In certain kinds of reading tasks psychologists thought it was relevant **that** people made errors, but they didn't think the **exact nature of the errors** was relevant.\n\n But after certain kinds of theories were developed (ones based on neural network models) they came to realise that the particular **kinds of errors** (e.g., if people swapped letters between words) was relevant.\n</blockquote>\n\nIn short, observations can't be completely divorced from theories.\n\nAnd experiments will presume the truth of certain theories (e.g., brain imaging experiments assume the validity of certain theories about brain function).\n\n\n## \"Objectivity\"\n\n<blockquote>\nFact's don't care about your feelings\n\n<cite style=\"text-align: right; display:block; font-style: italic\"> — Guy on the internet</cite>\n</blockquote>\n\n\nThe idea that science is **objective** in a _simple sense_ of \"objectivity\" is misleading. \n\nYour **conceptual framework**, and **theoretical assumptions**, and even your **knowledge and training** can play **a part** in *what kinds of observations* you can make or *what types of observation statements you can formulate*\n\n\"Objectivity\" **[doesn't mean]{.red}** observations free from theoretical assumptions (\"the view from nowhere\")\n\n---\n\n### \"Objectivity\" is more complex\n\n\"Objectivity\" [does mean]{.green}\n\n  - **Publicly** and independently verifiable methods\n  - **Recognising** theoretical assumptions\n  - **Theory/data that are open to revision** and improvement\n  - Free from **avoidable** forms of bias (confounds, cherry picking data, experimenter bias)\n \n<br>\n\nIt is also **objective** in the sense that despite all this, when you make the observations either the behaviour will happen or it won't, the detector will flash or it won't etc. _Your theory can't make things happen_.\n  \n\n\n\n## Deriving theories from facts\n\nThe second part of the **common-sense** view of science is that scientific knowledge is **derived** from facts. \n\nUsually this idea of **derived** means something like **logically derived**. We might sum up the view like this:\n\n\n<blockquote>\nScience = Facts + Logic  \n\n<cite style=\"text-align: right; display:block; font-style: italic\"> — Guy on the internet</cite>\n</blockquote>\n\n\n<br>\nTo understand what it might mean to **logically** derive scientific knowledge we need to know a bit about **logic**\n\n\n---\n\n### Deductive logic {.smallish}\n\nA deductive argument is called **valid** if the conclusions follow from the premises. \n\n:::: {.columns}\n::: {.column width=\"50%\"}\n**Example 1**   \n1. All research methods lectures are boring    \n2. This is a research methods lecture    \n3. (Therefore) this lecture is boring    \n\nIn this example, if we accept that (1) and (2) are true, then we have to accept (3) as true. We cannot accept (1) and (2) as true and then deny that (3) is true because we would be contradicting ourselves.\n:::\n\n::: {.column width=\"50%\"}\n**Example 2**  \n1. Most research methods lectures are boring   \n2. This is a research methods lecture     \n3. (Therefore) this lecture is boring      \n\nIn our new example, we can accept (1) and (2) as true without accepting (3) as true. That is, (3) does not **necessarily follow** from (1) and (2). It might just be a case of a research methods lecture that isn't boring.\n:::\n::::\n\nDeduction was only concerned with whether (3) follows from  (1) and (2). Not concerned with determining whether (1) and (2) are true or false. The argument assumes that (1) and (2) _are_ true, but it doesn't establish **truth** \n\n---\n\n### False but valid\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n**Example 3**   \n1. All pigs can fly   \n2. Percy is a pig   \n3. (Therefore) Percy can fly. \n:::\n\n::: {.column width=\"50%\"}\nThe conclusion is **valid**. However, it is also **false** because (1) is false.\n\nIt is **valid** because if we accept (1) and (2) we can have to accept (3)\n:::\n::::\n\n**logic** only tells us what follows from what. If there is truth in our premises, then there is truth in our conclusions. \n<br>\n\nIf our premises are false, then our conclusions will also be false.\n<br>\n\nDeductive logic is **truth-preserving**, but it can't tell us what is true and what is false. And the conclusion is just a *re-statement of the information contained in the premises*\n\nSo **deductive logic** can't create new knowledge. What can you do instead?\n\nWe need a way to go from **particular observations** to **generalizations** (this process is called **induction**)\n\n## Induction\n\nWe need a way to construct arguments of the following form:\n\n**Premises**    \n1. Emily the swan is white   \n2. Kevin the swan is white   \n3. ... the swan is white   \n \n**Conclusion**    \nAll swans are white   \n\n<br>\n\nBut the problem with arguments like this is that _all the premises may be true and yet the conclusion can be false_\n\n**Maybe** we just haven't observed the one swan that **isn't white**?\n\n## Collecting observations\n\nBut surely there are [good]{.green} and [bad]{.red} **inductive** arguments?\n\n- **More** observations better than **fewer** observations—_but how many is enough?_\n\n- Observations in many **different contexts**—_but what makes a context different and what makes differences **relevant**?_    \n\t- Different contexts should be **novel** in some sense     \n\t- That is, it should **not** just be **trivial** changes   \n\n- No **contradicting observations**—_but what about **probabilistic** phenomena_?\n\n**Clear** and **simple** rules aren't easy to come by.\n\nBut the bigger problem is **induction can never establish truth**.\n\nSo how do we ever **prove anything for certain in science**. The short answer is, **we don't**.\n\nWe can **never be certain** of **truth**.   \n\n## Using induction and deduction\n\n Instead of just **collecting** _confirmations_ we can employ **induction** and **deduction**\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n <img style=\"display:flex;margin-left:auto;margin-right:auto\" src=\"inductive-deductive.png\"></img>\n:::\n\n::: {.column width=\"50%\"}\n- Collect observations and use **induction** to come up with **general laws** and theories from **particular observations**\n\n- Use deduction to figure out what **logically follows** from these general laws and theories]\n:::\n::::\n\nThis approach nicely captures the idea of **testability**\n\nOur **theories** should make **predictions** about what we **expect to find** and we can **test** these predictions with more observations\n\n## Deduction and knowing what is **false**\n\nThe philosopher _Karl Popper_ also saw trouble with relying on **induction**. He wanted to put science on a firmer logical footing.\n\nTo do this, he proposed that while scientists can't use **deduction** to figure out what is **true**, they can use **deduction** to figure out what is **false**\n\n\nHe suggested that a key quality of **scientific theories** is that they should be **falsifiable**.\n\nTheories can come into existence through any means (wild speculation, guesses, dreams, or whatever), but once a theory has been proposed it has to be **rigorously and ruthlessly tested**\n\n---\n\n### Falsification of theories\n\n::::{.columns}\n:::{.column width=\"50%\"}\n**Confirmation**     \n**Premise:** A swan that was white was spotted in London at time *t*   \n\n**Conclusion:** All swans are white.   \n\nConclusion might be **true** or **false**, but it doesn't **logically** follow from the premise \n:::\n\n:::{.column width=\"50%\"}\n**Falsification**     \n**Premise:** A swan, which was not white, was spotted in Australia at time *t*.    \n\n**Conclusion:** Not all swans are white.   \n\nConclusion **logically** follows from the premise, so if the premise is **true** the conclusion is **true**. \n:::\n::::\n\n<br>\n\nWe can't **prove** the claim \"_all swans are white_\", but we can **reject it.**\n\n## Degrees of **falsifiability** {.smallish}\n\n**Good** theories are *falsifiable*, **better** theories are **_more falsifiable_**\n\n**Three theories:**   \n\n1. Mars moves in an elliptical orbit    \n2. Mars and Venus move in elliptical orbits   \n3. Planets move in elliptical orbits   \n\nOf these three theories, (1) is the least falsifiable and (3) is the most falsifiable. Why? For theory (1) only an observation of Mars could falsify it. But for theory (3), an observation Mars, Venus, Saturn, Neptune, or any other yet undiscovered planet would falsify it.\n\nBad theories are ones that can seemingly accommodate **any observation**\n\nIf **two outcomes** are possible and the theory can explain **outcome one** and **outcome two** then this is **bad**. What would be **evidence against the theory**?\n\n**[Good]{.green}** theories are **broad** in their **_applicability_** but **precise** in their **_predictions_**  \n\n## Encountering a falsifier\n\nWhat happens when you make an observation that falsifies a theory?\n\nThat is, you observe something that **contradicts** the theory you're testing. What do you do?\n\n**Your options:**\n\n- You could _abandon the theory_    \n\t- But what about _probabilistic theories_?   \n\t- And what about _auxiliary assumptions_?    \n\t \n- You could _modify or amend the theory_   \n\t- But are their _better_ ways and _worse_ ways to do this?   \n\n## Probabilistic theories \n\nTheories in **psychology** tend to be **probabilistic**. They make claims about how things are **on average**, not claims about how things are **in every case**.^[A probabilistic claim might say something like _on average_ \"men are taller than women\", but of course there are shorter men and taller women.]\n\nMuch of what we do with **statistics** is figuring out how to **test** and **specify** **probabilistic claims**. For example:    \n- What does it mean for things to be different **on average**    \n- How many cases do you have to observe before you have **evidence for** a probabilistic claim   \n- How many cases do you have to observe before you have **evidence against** a probabilistic claim (that you might previously have believed)    \n\nBut putting that aside, a **single** contradictory observation can't falsify a probabilistic claim because we will **sometimes expect** contradictions with probabilistic claims.\n\n\n## Abandoning the theory\n\nPutting aside the probabilistic nature of claims (or assuming you've seen enough contradictory examples), should these contradictory observations lead you to abandon the theory?\n\nAny experiment is not testing **one theory in isolation** but also relies on a range of auxiliary assumptions and other support theories.\n\nFor example, an experiment on memory using brain imaging is also making assumptions about the truth of theories related to physics and brain functioning, **besides** testing the theory about memory).\n\n\n---\n\n### The Duhem-Quine problem\n\nIt **may be the case** that what is actually at fault is one of these auxiliary assumptions and not **your theory**.  Telling which part of the **interconnected web** of theories is at fault can be tricky. Philosophers call this the _Duhem-Quine problem_.\n\n_Popper_ didn't have a good answer on how to figure out where to lay the blame for an _apparent_ falsification.\n\n_Popper_ also didn't think that theories should be abandoned _too quickly_.\n\nHe suggested some _dogmatism_, because at the start scientists might still be figuring out the details, and therefore they might just need to make some _tweaks_ and modify their theories.\n\n\n## Revising and amending theories\n\nBut if we decide to amend a theory, then how do we do this?\n\n**Theory**: All bread is nourishing     \n**Observation:** Bread eaten in a French village in 1951 was not nourishing^[[https://en.wikipedia.org/wiki/1951_Pont-Saint-Esprit_mass_poisoning](https://en.wikipedia.org/wiki/1951_Pont-Saint-Esprit_mass_poisoning)]\n\n**[Ad-hoc modification]{.red}**     \n_All bread expect bread eaten in a French village in 1951 is nourishing_     \n\nModification has fewer tests: Original theory can be tested by eating any bread. Modified theory can be tested by eating any bread **except** that particular bread.\n\n\n**[Acceptable modification]{.green}**   \n_All bread except bread made with flour containing ergot fungus is nourishing_\n\nModification leads to new tests: 1) Test the bread for the presence of fungus; 2) Cultivate fungus and make bread with it and test whether it nourishes; 3) Analyse fungus for poisons.   \n\n---\n\n## Problems with Popper's falsificationism  \n\n_Popper's_ focus on **falsifying** theories leads to a couple of problems:\n\n1. It can be difficult to figure out when to **abandon** theories and when to **amend** theories. \n\n    - Are all parts of the **theoretical web** of the same status?\n\n2. It can difficult to compare two theories to see which is \"better\"\n    - For example, if you have **Theory  A** and **Theory B** and neither has been falsified, which is the better theory? The one with _more **confirming** observations_? But then won't **trivial theories** will always win?\n\n\nThe philosopher _Imre Lakatos_ developed his idea of **research programmes**^[A _similar_ idea was developed by the philosopher _Thomas Kuhn_, but _Kuhn_ used the term **paradigms** for his idea.] as a reaction to these two problems.\n \n\n## Research programmes\n\nOne key aspect of _Lakatos's_ idea of **research programmes** is that not all **parts of a science are on par**\n\n- Some laws or principles are so fundamental they might be considered a **defining part of the science**.\n\n- Other parts might be more peripheral\n\n_Lakatos_ called these fundamental parts the **hard core** and the more peripheral parts the **protective belt**\n\nHe suggested that the **hard core** is resistant to _falsification_, so when an apparent falsifier is observed the blame is placed on theories in the **protective belt** \n\n**Research programmes** are defined by what is in their **hard core**\n\n---\n\n### Hard cores and protective belts\n\nWhat is in the **hard core** and what is in the **protective belt** might not always be explicit, but these might be some examples:\n\n- In Cognitive Science the **hard core** might include the theory that mind/brain is a _particular kind of computational system_ and the **protective belt** might include specific theories about how memory works\n\n- In the biomedical view of mental illness the **hard core** might include the theory that mental illness can be explained biochemically and the **protective belt** might include the dopamine theory of schizophrenia\n\nWhen apparent falsifications occur the **protective belt** is up for revision but the **hard core** stays intact. Falsifying the **hard core** amounts to abandoning the _research programme_ (more on this later)\n\n\n\n## Working within a research programme\n\nOn _Latakos's_ view, scientists work **within a research programme**. \n\nHe split guidelines for working within a research programme into a **negative** and **positive** heuristic, specifying what scientists **shouldn't** do but also what they **should** do\n\n- The _negative heuristic_ includes things like not abandoning the **hard core**\n\n- The _positive heuristic_ is harder to specify exactly, but it includes suggestions on how to supplement the protective belt to develop the research programme further\n\n\t- That is, it should specify a **programme of research** \n\n\t- The **research programme** should identify problems to solve\n\n---\n\n### Example of a research programme\n\n<img style=\"display:flex;margin-left:auto;margin-right:auto;width:55%\"  src=\"hardcore.png\" />\n\n<caption>Example of a research programme from Dienes (2008)</caption>\n\n## Progressive / degenerating programmes\n\n_Lakatos_ was also interested in comparing **research programmes**, something that is difficult to do on a _strictly_ falsificationist account.\n\nHe divided research programmes into those that are **progressive** and those that are **degenerating**\n\n- Progressive research programmes are coherent (i.e., have minimal contradictions)\n\n\t- And progressive research programmes make **novel** predictions that **follow naturally** from theories that are part of the programmes\n\n\t- These predictions are then confirmed by experiments\n\n- Degenerating research programmes are those that have faced so many falsifications that they have been modified to the point of being incoherent. \n\n\t- At this point, it's no longer sustainable to carry on modifying the protective belt, and instead, the hard core must be abandoned \n\n---\n\n### Moving from one programme to another\n\nWhen the hard core is abandoned then scientists move from one research programme into a new one. \n\nSome examples of this in psychology might include:\n\n1. The move from psychological behaviourism to cognitive science \n\n2. From classical cognitive science to embodied cognitive science\n\n3. From connectionism to deep neural networks \n\n4. From sociobiology to evolutionary psychology\n\nBut again, what is and isn't a **research programme** isn't always clear, because often the **hard core** and the **protective belt** are left _implicit_ and not made _explicit_\n\nHowever, I think it's valuable to keep these distinctions in mind as you move through your university career.\n\n# The end {.center-x}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}