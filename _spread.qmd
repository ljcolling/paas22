
## Measures of spread


at @fig-hist-width you'll see two data sets that are centred at the
same value but have very different amounts of variability. Both sets of data
have a mean of 0. But, as you can see, the values of one are spread out much
more widely than the values of the other.

```{r}
#| echo: false
#| warning: false
#| label: fig-hist-width
#| fig-cap: Histogram of two distributions with equal means but different spreads. *N = 10,000* in each case.
dist_narrow <- rnorm(10000, mean = 0, sd = 1)
dist_wide <- rnorm(10000, mean = 0, sd = 3)
tibble::tibble(
  narrrow = dist_narrow,
  wide = dist_wide
) |>
  tidyr::pivot_longer(1:2) |>
  ggplot2::ggplot(aes(
    x = value,
    # group = name,
    fill = name,
    alpha = name
  )) +
  geom_histogram(color = "black", position = "identity") +
  scale_alpha_manual(values = c(1, 0.7), guide = "none") +
  scale_fill_manual(values = c("seagreen", "blue"), guide = "none") +
  NULL
```


This is why, in addition to measures of central tendency, we also need measures
that tell us about the spread, or _dispersion_ of a variable. Once again, there
are several measures of spread available, and we'll talk about five of them:

1. Range

2. Interquartile range

3. Deviation

4. Variance

5. Standard deviation

<!-- FIXME: Add the visualisation in here? -->


### Range

The **range** of a variable is simply the distance between its smallest and
largest values. For example, if we gather a sample of 100 participants and the
youngest one is 17 years old, and the oldest one is 67 years old, then the range
of our age variable in this sample if 67 - 15 = `r 67 - 17` years.

Checking the range of a variable can tell us something about whether our data
makes sense. Let's say that we've run a study examining reading ability in
primary school age children. In this study, we've also measured the ages of the
children. If the range of our age variable is, for example, 50 years, then that
tells us that we've measured _at least_ one person that is not school age.

Beyond that, the range doesn't tell us much of the information we'd usually like
to know. This is because the range is _extremely_ **sensitive to outliers**.
What this means is that it only takes one extreme value to inflate the range. In
our school example, it might be that all but one of the people measured is
actually in the correct age range. But the range alone cannot tell us if this is
the case.

### Interquartile range

A slightly more useful measure than the range is the **interquartile range** or
IQR. The IQR is the distance between the 1st and 3rd quartiles of the data.
Quartiles, like the name suggests, are created by splitting the data into four
chunks where each chunk has the same number of observations. Or put another way,
the median splits the data into two where half the observations are higher than
the median and half the observations are lower than the median. Quartiles are
created by taking each of these halves and splitting them in half again. The
range covered by the middle two 25% chunks is the IQR. It is the range that
covers the middle 50% of the data.

The benefit of the IQR over a simple range is that the IQR is not sensitive to
occasional extreme values. This is because the bottom 25% and the top 25% are
discarded. However, by discarding these data, the IQR provides no information
about how spread these outer areas are.


### Deviation

Both the range and the IQR work by looking at the distance between only two
observations in the entire data. For the range, it's the distance between the
minimum point and the maximum. For the IQR, it's the distance between the
midpoint of the upper half and the midpoint of the lower half.

As a result, both these measures tend to be fairly course-grained. To get a more
fine-grained measure of the spread we could look at each data point and
calculate how far it is away from the typical value. Usually, this is done by
looking at how far away each data point is from the **mean**. 

This is known as the deviation.


<!-- FIXME: Add equation -->
<!--
If you click **show table** on the visualisation above, then you'll be able to
see the deviations..
-->

Because we are calculating this for every data point there will be as many
deviations as we have values for our variable. To get a _single measure_, we'll
have to perform another step.

One thing we could try doing is just to add up the numbers. But this won't work.
To see why, try adding a few points below. Add you add the points take a look at
the table below. The table has a column with all the points, and all the
deviations from the mean. Below the table you can see what happens when you add
up all those deviation values. What do you notice?

As you can see, they add up to zero. Because the mean is our midpoint, the
distances for all the points higher than the mean cancel out the distances for
all the points lower than the mean.

We can get around this problem by taking the square of the deviations before
adding them up. Squaring a number will turn a negative number into a positive
number, so when we add up all the numbers they'll no longer add up to 0.

Adding up all the numbers, however, leaves us with another problem. The sum of
the squared deviations gets bigger with bigger samples. That's not good because
even big samples can have a small amount of variation, while smaller samples can
vary a lot. We want our measure of spread to be able to capture this. Get around
this, we'll move on to our next measure of spread.


<!--
:::{.callout-tip}
#### Why square the values?

Why are the deviations squared? Couldn't we just work about the absolute value
instead? The **intuitive** explanation here is that squaring the values means
that squared deviances get bigger


:::
-->

### Variance

You next measure of spread is the **variance**. The **variance** gets around the
problem of the measure of spread just getting bigger when we have bigger
datasets. And it gets around this problem by just working out the _**average**
squared deviation_.

To work out the **average squared deviation** we would just divide the sum of
the squared deviations by the number of data points. However, 


:::{.callout-tip collapse="true"}

#### Why N-1 and not N? (optional)

The exact mathematical proof for why we divide the sum by _N - 1_ rather than
_N_ is beyond what you need to know for this course, but we can try build an
intuition for the reasoning behind it. If you don't follow all the reasoning
here, then don't worry. Come back to it at the end of the course and see if it
makes more sense.

We'll start off my going back an example of rolling dice. When we roll a dice
there's an equal chance of getting 1, or 2, or 3, or 4, or 5, or 6. We can use
this fact to describe our "population" from which any particular set of 6 dice
rolls will be a sample. We'll talk more about the idea of _theoretical
populations_ in [Lecture](). What would be the mean of this theoretical
population? It would be `r seq(1, 6, 1) |> mean()`. Why? We just add up 1, 2, 3,
4, 5, and 6, and divide it by 6, because in a *infinitely large sample* each
number would occur equally often. What would be the variance of this population?

To work that out we first work out the squared deviances, which would be
`r (seq(1, 6, 1) - 3.5)^2`. We'd then sum these values and divide it by 6. This
would give us about `r round(sum((seq(1, 6, 1) - 3.5)^2)/6,2)`. This our
population variance.

We know these values for a dice throw, but we often don't know these values for
the populations we're actually sampling from. When we collect a sample of data
we have to work out the mean and the variance with the set of numbers we
actually have. To work out the variance, we should be working out the deviances
from the **population mean**, but we don't know this value. So we have to work
out the deviances from the mean of our sample. But this means that each of our
deviances will, on average, be off by some amount. If we just take the average
of these deviances to work out our variance then our variances estimate will, on
average, be lower than the true population value. 

In our dice example, it will, _on average_ be $\frac{2.92}{6}$ or 0.49 lower
than the true value. And in general, it will be $\sigma^2/n$ lower than the true
value. We can correct for this **bias** by dividing the sum of the squared
deviances by *N - 1* rather than *N*.

:::


-----


